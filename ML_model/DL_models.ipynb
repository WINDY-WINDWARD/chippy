{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lovely</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok sound goood hehe</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>egg holder make ash wood shop link egg holder ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>buy book review help get amazon new release su...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eeek come im soo excite see thursday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  emotion\n",
       "0                                             lovely        3\n",
       "1                                ok sound goood hehe        3\n",
       "2  egg holder make ash wood shop link egg holder ...        3\n",
       "3  buy book review help get amazon new release su...        4\n",
       "4               eeek come im soo excite see thursday        1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build RNN model, Deep Belief Network model and compare their performance\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read in the data from the csv file\n",
    "emotionData = pd.read_csv(\"./emotion_data_v1.csv\")\n",
    "\n",
    "emotionData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToEmotion(emot):\n",
    "    if emot == 0:\n",
    "        return \"neutral\"\n",
    "    elif emot == 1:\n",
    "        return \"happy\"\n",
    "    elif emot == 2:\n",
    "        return \"sad\"\n",
    "    elif emot == 3:\n",
    "        return \"love\"\n",
    "    elif emot == 4:\n",
    "        return \"anger\"\n",
    "    elif emot == 5:\n",
    "        return \"fear\"\n",
    "    else:\n",
    "        return \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Prepare the data\n",
    "texts = emotionData.iloc[:, 0].values\n",
    "emotions = emotionData.iloc[:, 1].values\n",
    "texts = [str(text) for text in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# convert the texts to sequences\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "# pad the sequences\n",
    "maxlen = 100\n",
    "padded_sequences = pad_sequences(sequences, maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1641/1641 [==============================] - 34s 18ms/step - loss: 1.0241 - accuracy: 0.5985 - val_loss: 0.8133 - val_accuracy: 0.6788\n",
      "Epoch 2/10\n",
      "1641/1641 [==============================] - 31s 19ms/step - loss: 0.6812 - accuracy: 0.7439 - val_loss: 0.8234 - val_accuracy: 0.6774\n",
      "Epoch 3/10\n",
      "1641/1641 [==============================] - 31s 19ms/step - loss: 0.5309 - accuracy: 0.8032 - val_loss: 0.8990 - val_accuracy: 0.6787\n",
      "Epoch 4/10\n",
      "1641/1641 [==============================] - 29s 18ms/step - loss: 0.4298 - accuracy: 0.8428 - val_loss: 0.9873 - val_accuracy: 0.6713\n",
      "Epoch 5/10\n",
      "1641/1641 [==============================] - 29s 17ms/step - loss: 0.3568 - accuracy: 0.8674 - val_loss: 1.0730 - val_accuracy: 0.6702\n",
      "Epoch 6/10\n",
      "1641/1641 [==============================] - 31s 19ms/step - loss: 0.3158 - accuracy: 0.8805 - val_loss: 1.2498 - val_accuracy: 0.6652\n",
      "Epoch 7/10\n",
      "1641/1641 [==============================] - 29s 18ms/step - loss: 0.2818 - accuracy: 0.8922 - val_loss: 1.3050 - val_accuracy: 0.6614\n",
      "Epoch 8/10\n",
      "1641/1641 [==============================] - 31s 19ms/step - loss: 0.2501 - accuracy: 0.9039 - val_loss: 1.3869 - val_accuracy: 0.6620\n",
      "Epoch 9/10\n",
      "1641/1641 [==============================] - 30s 18ms/step - loss: 0.2314 - accuracy: 0.9115 - val_loss: 1.4835 - val_accuracy: 0.6624\n",
      "Epoch 10/10\n",
      "1641/1641 [==============================] - 28s 17ms/step - loss: 0.2105 - accuracy: 0.9190 - val_loss: 1.6188 - val_accuracy: 0.6592\n",
      "513/513 [==============================] - 5s 9ms/step - loss: 1.6612 - accuracy: 0.6560\n",
      "Accuracy: 65.603852\n",
      "Loss: 166.123366\n"
     ]
    }
   ],
   "source": [
    "#  emotions are encoded as integers from 0 to 5\n",
    "# convert to one-hot encoding\n",
    "emotions = to_categorical(emotions)\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, emotions, test_size=0.2, random_state=42)\n",
    "\n",
    "# build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(tokenizer.word_index)+1, 128, input_length=maxlen))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, validation_split=0.2)\n",
    "\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %f' % (accuracy*100))\n",
    "print('Loss: %f' % (loss*100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.argmax(y_train, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -685392331.63, time = 4.03s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -1372598534.66, time = 7.06s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -2059804729.74, time = 7.10s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -2747010928.69, time = 7.07s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -3434217132.71, time = 7.19s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -4121423331.43, time = 7.30s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -4808629534.34, time = 7.48s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -5495835731.53, time = 7.09s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -6183041933.78, time = 7.00s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -6870248133.38, time = 6.97s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -7557454335.85, time = 6.99s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -8244660534.58, time = 6.94s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -8931866734.40, time = 7.03s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -9619072934.67, time = 6.96s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -10306279133.85, time = 7.11s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -10993485340.48, time = 6.98s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -11680691533.82, time = 7.03s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -12367897736.19, time = 6.90s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -13055103938.67, time = 7.00s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -13742310142.45, time = 7.03s\n",
      "[BernoulliRBM] Iteration 21, pseudo-likelihood = -14429516333.36, time = 6.93s\n",
      "[BernoulliRBM] Iteration 22, pseudo-likelihood = -15116722536.82, time = 7.15s\n",
      "[BernoulliRBM] Iteration 23, pseudo-likelihood = -15803928737.53, time = 7.16s\n",
      "[BernoulliRBM] Iteration 24, pseudo-likelihood = -16491134938.24, time = 7.91s\n",
      "[BernoulliRBM] Iteration 25, pseudo-likelihood = -17178341135.19, time = 7.07s\n",
      "[BernoulliRBM] Iteration 26, pseudo-likelihood = -17865547336.34, time = 7.08s\n",
      "[BernoulliRBM] Iteration 27, pseudo-likelihood = -18552753542.99, time = 6.97s\n",
      "[BernoulliRBM] Iteration 28, pseudo-likelihood = -19239959740.84, time = 6.99s\n",
      "[BernoulliRBM] Iteration 29, pseudo-likelihood = -19927165941.54, time = 7.12s\n",
      "[BernoulliRBM] Iteration 30, pseudo-likelihood = -20614372138.96, time = 6.91s\n",
      "[BernoulliRBM] Iteration 31, pseudo-likelihood = -21301578336.02, time = 7.02s\n",
      "[BernoulliRBM] Iteration 32, pseudo-likelihood = -21988784538.27, time = 7.05s\n",
      "[BernoulliRBM] Iteration 33, pseudo-likelihood = -22675990740.20, time = 7.10s\n",
      "[BernoulliRBM] Iteration 34, pseudo-likelihood = -23363196944.98, time = 6.90s\n",
      "[BernoulliRBM] Iteration 35, pseudo-likelihood = -24050403143.14, time = 7.08s\n",
      "[BernoulliRBM] Iteration 36, pseudo-likelihood = -24737609337.58, time = 6.91s\n",
      "[BernoulliRBM] Iteration 37, pseudo-likelihood = -25424815541.26, time = 7.11s\n",
      "[BernoulliRBM] Iteration 38, pseudo-likelihood = -26112021741.55, time = 7.00s\n",
      "[BernoulliRBM] Iteration 39, pseudo-likelihood = -26799227939.70, time = 6.95s\n",
      "[BernoulliRBM] Iteration 40, pseudo-likelihood = -27486434140.42, time = 7.15s\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2099\n",
      "           1       0.35      1.00      0.52      5718\n",
      "           2       0.00      0.00      0.00      4108\n",
      "           3       0.00      0.00      0.00      2086\n",
      "           4       0.00      0.00      0.00      1940\n",
      "           5       0.00      0.00      0.00       452\n",
      "\n",
      "    accuracy                           0.35     16403\n",
      "   macro avg       0.06      0.17      0.09     16403\n",
      "weighted avg       0.12      0.35      0.18     16403\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[   0 2099    0    0    0    0]\n",
      " [   0 5718    0    0    0    0]\n",
      " [   0 4108    0    0    0    0]\n",
      " [   0 2086    0    0    0    0]\n",
      " [   0 1940    0    0    0    0]\n",
      " [   0  452    0    0    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karth\\.conda\\envs\\Avina\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\karth\\.conda\\envs\\Avina\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\karth\\.conda\\envs\\Avina\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#  build the Deep Belief Network model this sucks and takes forever\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "rbm = BernoulliRBM(random_state=0, verbose=True, n_iter=40)\n",
    "rbm.learning_rate = 0.06\n",
    "\n",
    "y_train = np.argmax(y_train, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "logistic = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "classifier = Pipeline(steps=[('rbm', rbm), ('logistic', logistic)])\n",
    "\n",
    "# Training RBM-Logistic Pipeline\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print()\n",
    "print(\"Classification report: \\n%s\\n\"\n",
    "      % (metrics.classification_report(y_test, y_pred)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Avina",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
